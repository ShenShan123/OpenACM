# 贝叶斯优化实现 - 使用说明

## 📁 文件说明

### ✅ 需要新增的文件（3个）
将下载的以下文件放到你的项目目录 `C:\Users\86189\Desktop\浅学一下\浅浅科研\buaa\pareto\NSGA_GNN\NSGA\`：

1. **acquisition.py** - EHVI采集函数实现
2. **bayesian_optimizer.py** - 贝叶斯优化器核心类  
3. **multiplier_bo.py** - 主运行脚本

### ✅ 保留的文件（不需要修改）
```
problem.py
individual.py
gnn_predictor.py
my_io.py
FEATURE.csv
Graph.csv
best_model_weights.pth
```

### ❌ 可以删除的文件（NSGA-II专用）
```
evolution.py
utils.py
population.py
```

你的 `multiplier.py` 可以保留作为参考，但不再运行。

---

## 🚀 快速开始

### 第1步：修改路径
由于我生成的代码中输出路径是 `/mnt/user-data/outputs/`，你需要在 **multiplier_bo.py** 中修改输出路径：

找到第86-102行，修改为你的Windows路径：
```python
# 第86行 - 结果文件
output_file = "C:/Users/86189/Desktop/浅学一下/浅浅科研/buaa/pareto/NSGA_GNN/NSGA/pareto_solutions_bo.txt"

# 第102行 - 图片文件
output_img = "C:/Users/86189/Desktop/浅学一下/浅浅科研/buaa/pareto/NSGA_GNN/NSGA/pareto_front_bo.png"
```

### 第2步：运行优化
```bash
cd C:\Users\86189\Desktop\浅学一下\浅浅科研\buaa\pareto\NSGA_GNN\NSGA
python multiplier_bo.py
```

---

## ⚙️ 参数调整

在 `multiplier_bo.py` 第74-79行：

```python
bo = BayesianOptimizer(
    problem,
    n_initial=200,              # 初始采样次数
    n_iterations=1000,          # 贝叶斯迭代次数
    n_candidates_per_iter=50000, # 每次采样候选点数
    ref_point=None              # 参考点（自动设置）
)
```

### 参数说明

| 参数 | 默认值 | 说明 | 建议范围 |
|------|--------|------|----------|
| n_initial | 200 | 初始随机采样次数 | 100-300 |
| n_iterations | 1000 | 贝叶斯优化迭代次数 | 500-1500 |
| n_candidates_per_iter | 50000 | 每次迭代采样候选点数 | 10000-100000 |
| ref_point | None | 参考点（自动=最差值×1.2） | None或[0.10, 350] |

**总评估次数** = n_initial + n_iterations = 1200次（对应你要求的1200轮）

---

## 📊 输出结果

### 1. 控制台输出示例
```
============================================================
开始多目标贝叶斯优化
目标: 最小化 MRED 和 PDP
============================================================

正在生成所有候选点...
总候选点数: 1953125

============================================================
开始贝叶斯优化
初始采样: 200次
贝叶斯迭代: 1000次
总评估次数: 1200次
============================================================

第1步: 初始随机采样...
初始采样: 100%|██████████| 200/200 [00:45<00:00,  4.42it/s]
自动设置参考点: [0.077, 340.5]

第2步: 贝叶斯优化迭代 (1000次)...
100%|██████████| 1000/1000 [18:30<00:00,  0.90it/s]

迭代 100/1000: 当前帕累托前沿有 28 个解
迭代 200/1000: 当前帕累托前沿有 41 个解
迭代 300/1000: 当前帕累托前沿有 52 个解
...

第3步: 提取最终帕累托前沿...
优化完成！帕累托前沿共有 73 个解
目标值范围:
  MRED: [0.004187, 0.064438]
  PDP:  [210.96, 285.49]

============================================================
优化结果统计
============================================================
帕累托前沿解的数量: 73

前5个最佳解 (按MRED排序):
1. state=[1,0,1,1,1,0,0,1,0]  MRED=0.004187  PDP=285.49
2. state=[1,0,1,1,0,0,0,1,0]  MRED=0.004237  PDP=284.34
...

前5个最佳解 (按PDP排序):
1. state=[4,4,4,4,4,4,4,4,3]  MRED=0.060044  PDP=211.02
2. state=[4,4,4,4,4,4,3,3,3]  MRED=0.064438  PDP=210.96
...
```

### 2. 文件输出
- **pareto_solutions_bo.txt** - 帕累托前沿详细数据
- **pareto_front_bo.png** - 帕累托前沿可视化图

---

## 🔄 与NSGA-II对比

| 指标 | NSGA-II | 贝叶斯优化 | 说明 |
|------|---------|-----------|------|
| 评估次数 | 960,000 | 1,200 | 贝叶斯减少800倍 |
| 运行时间 | 长 | 短（快800倍） | 假设单次GNN推理时间相同 |
| 前沿解数量 | ~800个 | ~50-100个 | NSGA-II更密集 |
| 解的质量 | 好 | 通常更好 | 贝叶斯智能选点 |
| 适用场景 | GNN快，要密集前沿 | 减少计算量 | - |

---

## 💡 常见问题

### Q1: 为什么解的数量比NSGA-II少？
因为贝叶斯优化只评估1200个点，NSGA-II评估96万个点。

**解决方法**：
- 增加评估次数：`n_initial=500, n_iterations=2500`（总计3000次）
- 或在贝叶斯找到的区域用NSGA-II细化（混合策略）

### Q2: 如何加速运行？
减小 `n_candidates_per_iter`：
```python
n_candidates_per_iter=10000  # 从50000降到10000
```
牺牲一点全局搜索能力，但速度提升5倍。

### Q3: 内存不足怎么办？
如果生成195万个候选点占用内存太大，在 `bayesian_optimizer.py` 第52行注释掉预生成：
```python
# self.all_candidates = list(itertools.product(...))
# 改为在 _sample_candidates 中动态生成
```

### Q4: 结果一定比NSGA-II好吗？
不一定"更好"，但在**相同评估预算**下，贝叶斯优化通常找到更优质的解。

### Q5: 可以并行运行吗？
当前实现是串行的。如果要并行，需要修改为批量采集（q-EHVI），建议使用BoTorch库。

---

## 🛠️ 技术细节

### 高斯过程（GP）
- **核函数**: RBF核（径向基函数）
- **分离建模**: MRED和PDP各自独立的GP
- **尺度处理**: StandardScaler标准化

### EHVI计算
- **方法**: 蒙特卡洛采样
- **采样次数**: 1000次/候选点
- **参考点**: 自动设置为最差值×1.2

### 候选点策略
- **总空间**: 5^9 = 1,953,125个点
- **每次采样**: 随机50,000个未评估点
- **GP预测**: 批量预测加速

---

## 📦 依赖包

```bash
pip install numpy scipy scikit-learn matplotlib tqdm torch dgl --break-system-packages
```

---

## 🎯 推荐使用场景

### 适合用贝叶斯优化：
- ✅ GNN推理较慢（>10ms/次）
- ✅ 想快速找到几个好解
- ✅ 计算资源有限
- ✅ 想探索特定区域

### 适合用NSGA-II：
- ✅ GNN推理很快（<1ms/次）
- ✅ 需要密集的帕累托前沿（数百个解）
- ✅ 有充足计算时间
- ✅ 想全局搜索

### 混合策略（最优）：
1. 先用贝叶斯优化200次找有潜力的区域
2. 在这些区域用NSGA-II细化搜索1000代

---

## 📞 问题反馈

如果运行出错，检查：
1. 所有文件是否在同一目录
2. `my_io.py` 和 `gnn_predictor.py` 中的路径是否正确
3. GPU/CPU设备设置是否正确

祝优化顺利！🎉
